{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('train.csv')\n",
    "dt=pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train=df.drop(columns=['label']).to_numpy().reshape((-1,28,28,1))/255\n",
    "label=df['label'].to_numpy()\n",
    "test=dt.to_numpy().reshape((-1,28,28,1))/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen =tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "        samplewise_center=False,  # set each sample mean to 0\n",
    "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "        samplewise_std_normalization=False,  # divide each input by its std\n",
    "        zca_whitening=False,  # apply ZCA whitening\n",
    "        rotation_range=10,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "        zoom_range = 0.1, # Randomly zoom image \n",
    "        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
    "        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
    "        horizontal_flip=False,  # randomly flip images\n",
    "        vertical_flip=False)  # randomly flip images\n",
    "\n",
    "\n",
    "datagen.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Conv2D(32,kernel_size=(3,3),input_shape=(28,28,1),use_bias=True,activation='relu'))\n",
    "model.add(tf.keras.layers.MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
    "model.add(tf.keras.layers.Dropout(0.25))\n",
    "model.add(tf.keras.layers.Conv2D(128,kernel_size=(4,4),use_bias=True,activation='relu'))\n",
    "model.add(tf.keras.layers.MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
    "model.add(tf.keras.layers.Dropout(0.2))\n",
    "model.add(tf.keras.layers.Conv2D(256,kernel_size=(4,4),use_bias=True,activation='relu'))\n",
    "model.add(tf.keras.layers.MaxPool2D(pool_size=(2,2)))\n",
    "model.add(tf.keras.layers.Dropout(0.2))\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "model.add(tf.keras.layers.Dense(128,activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(32,activation='relu'))\n",
    "model.add(tf.keras.layers.BatchNormalization())\n",
    "#model.add(tf.keras.layers.Dropout(0.25))\n",
    "model.add(tf.keras.layers.Dense(10,activation=tf.nn.softmax))\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 42000 samples\n",
      "Epoch 1/20\n",
      "42000/42000 [==============================] - 14s 341us/sample - loss: 0.0015 - acc: 0.9995\n",
      "Epoch 2/20\n",
      "42000/42000 [==============================] - 14s 339us/sample - loss: 0.0023 - acc: 0.9991\n",
      "Epoch 3/20\n",
      "42000/42000 [==============================] - 14s 339us/sample - loss: 0.0023 - acc: 0.9994\n",
      "Epoch 4/20\n",
      "42000/42000 [==============================] - 14s 338us/sample - loss: 0.0029 - acc: 0.9991\n",
      "Epoch 5/20\n",
      "42000/42000 [==============================] - 14s 339us/sample - loss: 0.0026 - acc: 0.9992\n",
      "Epoch 6/20\n",
      "42000/42000 [==============================] - 14s 339us/sample - loss: 0.0022 - acc: 0.9993\n",
      "Epoch 7/20\n",
      "42000/42000 [==============================] - 14s 340us/sample - loss: 0.0012 - acc: 0.9996\n",
      "Epoch 8/20\n",
      "42000/42000 [==============================] - 14s 340us/sample - loss: 0.0025 - acc: 0.9993\n",
      "Epoch 9/20\n",
      "42000/42000 [==============================] - 14s 340us/sample - loss: 0.0028 - acc: 0.9992\n",
      "Epoch 10/20\n",
      "42000/42000 [==============================] - 14s 342us/sample - loss: 0.0024 - acc: 0.9994\n",
      "Epoch 11/20\n",
      "42000/42000 [==============================] - 14s 343us/sample - loss: 0.0021 - acc: 0.9994\n",
      "Epoch 12/20\n",
      "42000/42000 [==============================] - 14s 339us/sample - loss: 0.0017 - acc: 0.9995\n",
      "Epoch 13/20\n",
      "42000/42000 [==============================] - 14s 339us/sample - loss: 0.0040 - acc: 0.9989\n",
      "Epoch 14/20\n",
      "42000/42000 [==============================] - 14s 340us/sample - loss: 0.0020 - acc: 0.9994\n",
      "Epoch 15/20\n",
      "42000/42000 [==============================] - 14s 341us/sample - loss: 0.0030 - acc: 0.9990\n",
      "Epoch 16/20\n",
      "42000/42000 [==============================] - 14s 339us/sample - loss: 0.0023 - acc: 0.9992\n",
      "Epoch 17/20\n",
      "42000/42000 [==============================] - 14s 342us/sample - loss: 8.7886e-04 - acc: 0.9997\n",
      "Epoch 18/20\n",
      "42000/42000 [==============================] - 14s 341us/sample - loss: 0.0026 - acc: 0.9992\n",
      "Epoch 19/20\n",
      "42000/42000 [==============================] - 14s 341us/sample - loss: 0.0020 - acc: 0.9993\n",
      "Epoch 20/20\n",
      "42000/42000 [==============================] - 14s 344us/sample - loss: 0.0020 - acc: 0.9995\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x200bb71bfd0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train,label,epochs=80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "result=model.predict(test)\n",
    "ans=np.argmax(result,axis=1)\n",
    "answer=pd.read_csv('sample_submission.csv')\n",
    "answer['Label']=ans\n",
    "ans=np.argmax(result,axis=1)\n",
    "answer.index=answer['ImageId']\n",
    "answer.drop(columns=['ImageId']).to_csv('answer.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
