{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('train.csv')\n",
    "dt=pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train=df.drop(columns=['label']).to_numpy().reshape((-1,28,28,1))/255\n",
    "label=df['label'].to_numpy()\n",
    "test=dt.to_numpy().reshape((-1,28,28,1))/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen =tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "        samplewise_center=False,  # set each sample mean to 0\n",
    "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "        samplewise_std_normalization=False,  # divide each input by its std\n",
    "        zca_whitening=False,  # apply ZCA whitening\n",
    "        rotation_range=10,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "        zoom_range = 0.1, # Randomly zoom image \n",
    "        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
    "        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
    "        horizontal_flip=False,  # randomly flip images\n",
    "        vertical_flip=False)  # randomly flip images\n",
    "\n",
    "\n",
    "datagen.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Conv2D(32,kernel_size=(3,3),input_shape=(28,28,1),use_bias=True,activation='relu'))\n",
    "model.add(tf.keras.layers.MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
    "model.add(tf.keras.layers.Dropout(0.25))\n",
    "model.add(tf.keras.layers.Conv2D(128,kernel_size=(4,4),use_bias=True,activation='relu'))\n",
    "model.add(tf.keras.layers.MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
    "model.add(tf.keras.layers.Dropout(0.2))\n",
    "model.add(tf.keras.layers.Conv2D(256,kernel_size=(4,4),use_bias=True,activation='relu'))\n",
    "model.add(tf.keras.layers.MaxPool2D(pool_size=(2,2)))\n",
    "model.add(tf.keras.layers.Dropout(0.2))\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "model.add(tf.keras.layers.Dense(128,activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(32,activation='relu'))\n",
    "model.add(tf.keras.layers.BatchNormalization())\n",
    "model.add(tf.keras.layers.Dense(10,activation=tf.nn.softmax))\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 42000 samples\n",
      "Epoch 1/30\n",
      "42000/42000 [==============================] - 14s 334us/sample - loss: 0.0040 - acc: 0.9989\n",
      "Epoch 2/30\n",
      "42000/42000 [==============================] - 14s 329us/sample - loss: 0.0042 - acc: 0.9986\n",
      "Epoch 3/30\n",
      "42000/42000 [==============================] - 14s 324us/sample - loss: 0.0039 - acc: 0.9987\n",
      "Epoch 4/30\n",
      "42000/42000 [==============================] - 14s 327us/sample - loss: 0.0044 - acc: 0.9985\n",
      "Epoch 5/30\n",
      "42000/42000 [==============================] - 14s 325us/sample - loss: 0.0032 - acc: 0.9991\n",
      "Epoch 6/30\n",
      "42000/42000 [==============================] - 13s 321us/sample - loss: 0.0036 - acc: 0.9990\n",
      "Epoch 7/30\n",
      "42000/42000 [==============================] - 14s 322us/sample - loss: 0.0034 - acc: 0.9989\n",
      "Epoch 8/30\n",
      "42000/42000 [==============================] - 13s 316us/sample - loss: 0.0036 - acc: 0.9987\n",
      "Epoch 9/30\n",
      "42000/42000 [==============================] - 13s 319us/sample - loss: 0.0038 - acc: 0.9988\n",
      "Epoch 10/30\n",
      "42000/42000 [==============================] - 13s 317us/sample - loss: 0.0030 - acc: 0.9991\n",
      "Epoch 11/30\n",
      "42000/42000 [==============================] - 13s 317us/sample - loss: 0.0036 - acc: 0.9988\n",
      "Epoch 12/30\n",
      "42000/42000 [==============================] - 13s 318us/sample - loss: 0.0030 - acc: 0.9991\n",
      "Epoch 13/30\n",
      "42000/42000 [==============================] - 13s 319us/sample - loss: 0.0027 - acc: 0.9992\n",
      "Epoch 14/30\n",
      "42000/42000 [==============================] - 13s 317us/sample - loss: 0.0037 - acc: 0.9989\n",
      "Epoch 15/30\n",
      "42000/42000 [==============================] - 13s 318us/sample - loss: 0.0029 - acc: 0.9990\n",
      "Epoch 16/30\n",
      "42000/42000 [==============================] - 13s 319us/sample - loss: 0.0035 - acc: 0.9989\n",
      "Epoch 17/30\n",
      "42000/42000 [==============================] - 13s 317us/sample - loss: 0.0023 - acc: 0.9991\n",
      "Epoch 18/30\n",
      "42000/42000 [==============================] - 13s 319us/sample - loss: 0.0027 - acc: 0.9991\n",
      "Epoch 19/30\n",
      "42000/42000 [==============================] - 13s 317us/sample - loss: 0.0027 - acc: 0.9991\n",
      "Epoch 20/30\n",
      "42000/42000 [==============================] - 13s 318us/sample - loss: 0.0030 - acc: 0.9990\n",
      "Epoch 21/30\n",
      "42000/42000 [==============================] - 13s 320us/sample - loss: 0.0036 - acc: 0.9990\n",
      "Epoch 22/30\n",
      "42000/42000 [==============================] - 13s 317us/sample - loss: 0.0017 - acc: 0.9994\n",
      "Epoch 23/30\n",
      "42000/42000 [==============================] - 13s 317us/sample - loss: 0.0031 - acc: 0.9991\n",
      "Epoch 24/30\n",
      "42000/42000 [==============================] - 13s 319us/sample - loss: 0.0025 - acc: 0.9992\n",
      "Epoch 25/30\n",
      "42000/42000 [==============================] - 13s 319us/sample - loss: 0.0026 - acc: 0.9992\n",
      "Epoch 26/30\n",
      "42000/42000 [==============================] - 13s 317us/sample - loss: 0.0018 - acc: 0.9995\n",
      "Epoch 27/30\n",
      "42000/42000 [==============================] - 13s 317us/sample - loss: 0.0021 - acc: 0.9994\n",
      "Epoch 28/30\n",
      "42000/42000 [==============================] - 13s 317us/sample - loss: 0.0024 - acc: 0.9991\n",
      "Epoch 29/30\n",
      "42000/42000 [==============================] - 13s 317us/sample - loss: 0.0029 - acc: 0.9993\n",
      "Epoch 30/30\n",
      "42000/42000 [==============================] - 13s 318us/sample - loss: 0.0036 - acc: 0.9988\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x284b6e14ef0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train,label,epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "result=model.predict(test)\n",
    "ans=np.argmax(result,axis=1)\n",
    "answer=pd.read_csv('sample_submission.csv')\n",
    "answer['Label']=ans\n",
    "ans=np.argmax(result,axis=1)\n",
    "answer.index=answer['ImageId']\n",
    "answer.drop(columns=['ImageId']).to_csv('answer.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully submitted to Digit Recognizer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0.00/235k [00:00<?, ?B/s]\n",
      "  3%|3         | 8.00k/235k [00:00<00:07, 32.2kB/s]\n",
      " 41%|####      | 96.0k/235k [00:00<00:03, 44.9kB/s]\n",
      " 51%|#####1    | 120k/235k [00:00<00:02, 54.0kB/s] \n",
      " 82%|########1 | 192k/235k [00:00<00:00, 72.8kB/s]\n",
      " 92%|#########1| 216k/235k [00:00<00:00, 89.4kB/s]\n",
      "100%|##########| 235k/235k [00:10<00:00, 22.2kB/s]\n"
     ]
    }
   ],
   "source": [
    "!kaggle competitions submit digit-recognizer -f answer.csv -m \"Latest Submission\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fileName    date                 description        status    publicScore  privateScore  \n",
      "----------  -------------------  -----------------  --------  -----------  ------------  \n",
      "answer.csv  2019-06-24 03:58:54  Latest Submission  complete  0.99071      None          \n",
      "answer.csv  2019-06-24 03:38:42  Latest Submission  complete  0.99071      None          \n",
      "answer.csv  2019-06-12 19:13:38  Latest Submission  complete  0.99428      None          \n",
      "answer.csv  2019-06-01 18:02:27  None               complete  0.99400      None          \n",
      "answer.csv  2019-06-01 17:55:14  None               complete  0.99542      None          \n",
      "answer.csv  2019-06-01 17:39:41  None               complete  0.99428      None          \n",
      "answer.csv  2019-05-27 18:47:30  None               complete  0.99300      None          \n",
      "answer.csv  2019-05-27 18:39:27  None               complete  0.99357      None          \n",
      "answer.csv  2019-05-27 18:30:37  None               complete  0.99314      None          \n",
      "answer.csv  2019-05-27 18:25:51  None               complete  0.99200      None          \n",
      "answer.csv  2019-05-27 18:12:26  None               complete  0.98871      None          \n",
      "answer.csv  2019-05-25 20:02:52  None               complete  0.98771      None          \n",
      "answer.csv  2019-05-25 19:50:34  None               complete  0.99257      None          \n",
      "answer.csv  2019-05-25 19:45:44  None               complete  0.98800      None          \n",
      "answer.csv  2019-05-25 19:25:06  None               complete  0.96442      None          \n",
      "answer.csv  2019-05-25 19:16:17                     complete  0.98800      None          \n",
      "answer.csv  2019-05-25 19:15:24  None               error     None         None          \n",
      "answer.csv  2019-05-19 11:27:41                     complete  0.97828      None          \n",
      "answer.csv  2019-05-19 11:24:33                     error     None         None          \n",
      "answer.csv  2019-05-19 11:22:05  None               error     None         None          \n"
     ]
    }
   ],
   "source": [
    "!kaggle competitions submissions digit-recognizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0624 09:52:07.991994  7612 deprecation.py:506] From d:\\python\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:97: calling GlorotUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "W0624 09:52:07.991994  7612 deprecation.py:506] From d:\\python\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:97: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "W0624 09:52:08.175997  7612 deprecation.py:506] From d:\\python\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:97: calling Ones.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "model.save('my_model.h5') \n",
    "\n",
    "model = load_model('my_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
